{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data import + clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import random as rn\n",
    "import sklearn\n",
    "# from scipy import stats\n",
    "# import math\n",
    "import re\n",
    "\n",
    "from sklearn.preprocessing import  LabelEncoder #OneHotEncoder\n",
    "from sklearn import ensemble\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV,cross_val_score\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error,accuracy_score\n",
    "\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "totDF = pd.read_csv('../../data/processed/Cleaned_Data_Set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_per_year = 2000\n",
    "\n",
    "dwnSmplDF = totDF.groupby('birth_year',group_keys = False).apply(lambda x: x.sample(sample_per_year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = re.compile('.*reporting')\n",
    "r2 = re.compile('.*imputed')\n",
    "\n",
    "cols_to_drop1 = list(filter((r1.match), totDF.columns))\n",
    "cols_to_drop2 = list(filter((r2.match), totDF.columns))\n",
    "cols_to_drop3 = ['admit_NICU']\n",
    "cols_to_drop = cols_to_drop1 + cols_to_drop2 + cols_to_drop3\n",
    "\n",
    "cols_to_keep = [col for col in totDF.columns if col not in cols_to_drop]\n",
    "\n",
    "X = dwnSmplDF[cols_to_keep].copy()\n",
    "target = dwnSmplDF[['admit_NICU']].copy()\n",
    "# X = totDF[cols_to_keep].copy()\n",
    "# target = totDF[['admit_NICU']].copy()\n",
    "\n",
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "catDF = X.select_dtypes(include=object).copy()\n",
    "numDF = X.select_dtypes(include=numerics).copy() #only numeric columns\n",
    "\n",
    "le = LabelEncoder()\n",
    "catDF = catDF.apply(le.fit_transform)\n",
    "encoded_target = target.apply(le.fit_transform)\n",
    "\n",
    "cl_df = pd.concat([numDF,catDF],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:715: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.98 s, sys: 281 ms, total: 4.26 s\n",
      "Wall time: 1min 24s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators='warn', n_jobs=None,\n",
       "                                              oob_score=False, random_state=108,\n",
       "                                              verbose=0, warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid=[{'min_samples_leaf': [100, 10, 1],\n",
       "                          'min_samples_split': [100, 10, 2],\n",
       "                          'n_estimators': array([ 50,  55,  61,  66,  72,  77,  83,  88,  94, 100])}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomForest = ensemble.RandomForestClassifier()\n",
    "grid_para_forest = [{\n",
    "\t'n_estimators': np.linspace(50,int(np.sqrt(len(cl_df))),10,dtype=int),\n",
    "\t'min_samples_split' : [100,10,2],\n",
    "\t'min_samples_leaf' : [100,10,1]\n",
    "}]\n",
    "randomForest.set_params(random_state=108)\n",
    "grid_search_forest = GridSearchCV(randomForest, grid_para_forest, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "%time grid_search_forest.fit(cl_df, encoded_target) #put in the df here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "sample size: 10000\n",
      "best param : {'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "best score : 0.9491\n",
      "r2         : 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    '''Random Forest\n",
    "sample size: {0}\n",
    "best param : {1}\n",
    "best score : {2}\n",
    "r2         : {3}'''\\\n",
    "      .format(len(encoded_target), \\\n",
    "              grid_search_forest.best_params_,\\\n",
    "              grid_search_forest.best_score_, \\\n",
    "              r2_score(encoded_target, grid_search_forest.predict(cl_df)))\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1544: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11min 32s, sys: 10.6 s, total: 11min 43s\n",
      "Wall time: 11min 54s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10000.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=-1, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_1 = linear_model.LogisticRegression()\n",
    "logit_1.set_params(C=1e4, n_jobs=-1)\n",
    "%time logit_1.fit(cl_df, encoded_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample size: 10000 \n",
      "score: 0.9473\n",
      "r2: 0.3049125488527581\n"
     ]
    }
   ],
   "source": [
    "print('sample size: {0} \\nscore: {1}\\nr2: {2}'.format(len(encoded_target), \\\n",
    "                                                      logit_1.score(cl_df, encoded_target), \\\n",
    "                                                      r2_score(encoded_target, logit_1.predict(cl_df))))\n",
    "\n",
    "print('sample size: {0} \\nscore: {1}\\nr2: {2}'.format(len(encoded_target), \\\n",
    "                                                      logit_1.score(cl_df, encoded_target), \\\n",
    "                                                      r2_score(encoded_target, logit_1.predict(cl_df))))\n",
    "\n",
    "print('sample size: {0} \\nscore: {1}\\nr2: {2}'.format(len(encoded_target), \\\n",
    "                                                      logit_1.score(cl_df, encoded_target), \\\n",
    "                                                      r2_score(encoded_target, logit_1.predict(cl_df))))\n",
    "\n",
    "print('sample size: {0} \\nscore: {1}\\nr2: {2}'.format(len(encoded_target), \\\n",
    "                                                      logit_1.score(cl_df, encoded_target), \\\n",
    "                                                      r2_score(encoded_target, logit_1.predict(cl_df))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample size: 1000000 \n",
      "score: 0.940666\n",
      "r2: 0.27437829660503155\n"
     ]
    }
   ],
   "source": [
    "print('sample size: {0} \\nscore: {1}\\nr2: {2}'.format(len(encoded_target), \\\n",
    "                                                      logit_1.score(cl_df, encoded_target), \\\n",
    "                                                      r2_score(encoded_target, logit_1.predict(cl_df))))\n",
    "#11min 54sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
