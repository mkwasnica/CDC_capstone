{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import random as rn\n",
    "import sklearn\n",
    "# from scipy import stats\n",
    "# import math\n",
    "import re\n",
    "\n",
    "from sklearn.preprocessing import  LabelEncoder #OneHotEncoder\n",
    "# from sklearn import ensemble\n",
    "from sklearn import linear_model\n",
    "\n",
    "# from sklearn.model_selection import GridSearchCV,cross_val_score\n",
    "# from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error,accuracy_score\n",
    "\n",
    "# # from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn import linear_model\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, RidgeCV, LassoCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "totDF = pd.read_csv('../../data/processed/Cleaned_Data_Set.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning / Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = re.compile('.*reporting')\n",
    "r2 = re.compile('.*imputed')\n",
    "\n",
    "cols_to_drop1 = list(filter((r1.match), totDF.columns))\n",
    "cols_to_drop2 = list(filter((r2.match), totDF.columns))\n",
    "cols_to_drop3 = ['admit_NICU']\n",
    "cols_to_drop = cols_to_drop1 + cols_to_drop2 + cols_to_drop3\n",
    "\n",
    "cols_to_keep = [col for col in totDF.columns if col not in cols_to_drop]\n",
    "\n",
    "X_and_target = totDF[cols_to_keep + ['admit_NICU']].copy()\n",
    "\n",
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "catDF = X_and_target.select_dtypes(include=object).copy()\n",
    "numDF = X_and_target.select_dtypes(include=numerics).copy() #only numeric columns\n",
    "\n",
    "le = LabelEncoder()\n",
    "catDF = catDF.apply(le.fit_transform)\n",
    "\n",
    "concat_df = pd.concat([numDF,catDF],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size_list = [100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample size : 500\n",
      "\n",
      "CPU times: user 74.8 ms, sys: 12.5 ms, total: 87.3 ms\n",
      "Wall time: 135 ms\n",
      "\n",
      "score    : 0.934\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#pure GLM\n",
    "\n",
    "for sample_per_year in sample_size_list:\n",
    "    dwnSmplDF = concat_df.groupby('birth_year',group_keys = False).apply(lambda x: x.sample(sample_per_year))\n",
    "    \n",
    "    cl_df = dwnSmplDF[cols_to_keep]\n",
    "    encoded_target = dwnSmplDF['admit_NICU']\n",
    "    \n",
    "    glm = linear_model.LogisticRegression(solver = 'saga', \n",
    "                                              multi_class='auto', \n",
    "                                              n_jobs = -1,\n",
    "                                              C = 1e4)\n",
    "    print('sample size : %d\\n' % (sample_per_year*5))\n",
    "    %time glm.fit(cl_df, encoded_target)\n",
    "    print('\\nscore    : {0}'.format(glm.score(cl_df, encoded_target)))\n",
    "    print('-'*50)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#GLM with Cross Validation\n",
    "for sample_per_year in sample_size_list:\n",
    "    dwnSmplDF = concat_df.groupby('birth_year',group_keys = False).apply(lambda x: x.sample(sample_per_year))\n",
    "    \n",
    "    cl_df = dwnSmplDF[cols_to_keep]\n",
    "    encoded_target = dwnSmplDF['admit_NICU']\n",
    "    \n",
    "    glm_CV = linear_model.LogisticRegressionCV(#Cs = int(1e4),\n",
    "                                                cv = 5,\n",
    "                                                solver = 'saga',\n",
    "                                                n_jobs = -1,\n",
    "                                                random_state = 108\n",
    "                                               ).fit(cl_df, encoded_target)\n",
    "    print('sample size : %d\\n' % (sample_per_year*5))\n",
    "    %time glm_CV.fit(cl_df, encoded_target)\n",
    "    print('\\nscore    : {0}'.format(glm_CV.score(cl_df, encoded_target)))\n",
    "    print('-'*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "sample size : 500\n",
    "\n",
    "CPU times: user 6min 47s, sys: 1min 26s, total: 8min 14s\n",
    "Wall time: 1min 54s\n",
    "\n",
    "score    : 0.932\n",
    "--------------------------------------------------\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GLM with Lasso Penalty\n",
    "\n",
    "for sample_per_year in sample_size_list:\n",
    "    dwnSmplDF = concat_df.groupby('birth_year',group_keys = False).apply(lambda x: x.sample(sample_per_year))\n",
    "    \n",
    "    cl_df = dwnSmplDF[cols_to_keep]\n",
    "    encoded_target = dwnSmplDF['admit_NICU']\n",
    "    \n",
    "    glm_lasso = linear_model.LogisticRegression(penalty = 'l1', \n",
    "                                              solver = 'saga', \n",
    "                                              multi_class='auto', \n",
    "                                              n_jobs = -1,\n",
    "                                              C = 1e4)\n",
    "    print('sample size : %d\\n' % (sample_per_year*5))\n",
    "    %time glm_lasso.fit(cl_df, encoded_target)\n",
    "    print('\\nscore    : {0}'.format(glm_lasso.score(cl_df, encoded_target)))\n",
    "    print('-'*50)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample size : 500\n",
      "\n",
      "CPU times: user 2.87 s, sys: 97.3 ms, total: 2.96 s\n",
      "Wall time: 571 ms\n",
      "\n",
      "score    : 0.914\n",
      "--------------------------------------------------\n",
      "sample size : 5000\n",
      "\n",
      "CPU times: user 2min, sys: 577 ms, total: 2min 1s\n",
      "Wall time: 17.4 s\n",
      "\n",
      "score    : 0.9308\n",
      "--------------------------------------------------\n",
      "sample size : 50000\n",
      "\n",
      "CPU times: user 22min 12s, sys: 2.49 s, total: 22min 14s\n",
      "Wall time: 3min 17s\n",
      "\n",
      "score    : 0.9245\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#GLM with Lasso Penalty and Cross Validation\n",
    "\n",
    "sample_size_list = [100,1000,10000]\n",
    "\n",
    "for sample_per_year in sample_size_list:\n",
    "    dwnSmplDF = concat_df.groupby('birth_year',group_keys = False).apply(lambda x: x.sample(sample_per_year))\n",
    "    cl_df = dwnSmplDF[cols_to_keep]\n",
    "    encoded_target = dwnSmplDF['admit_NICU']\n",
    "    \n",
    "    glm_lassoCV = linear_model.LogisticRegressionCV(#Cs = int(1e4),\n",
    "                                                cv = 5,\n",
    "                                                penalty = 'l1',\n",
    "                                                solver = 'saga',\n",
    "                                                n_jobs = -1,\n",
    "                                                random_state = 108\n",
    "                                               ).fit(cl_df, encoded_target)\n",
    "    print('sample size : %d\\n' % (sample_per_year*5))\n",
    "    %time glm_lassoCV.fit(cl_df, encoded_target)\n",
    "    print('\\nscore    : {0}'.format(glm_lassoCV.score(cl_df, encoded_target)))\n",
    "    print('-'*50)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample size : 100000\n",
      "\n",
      "CPU times: user 1h 8min 3s, sys: 13.1 s, total: 1h 8min 16s\n",
      "Wall time: 5h 24min 52s\n",
      "\n",
      "score    : 0.92539\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#GLM with Lasso Penalty and Cross Validation\n",
    "\n",
    "sample_size_list = [20000]\n",
    "\n",
    "for sample_per_year in sample_size_list:\n",
    "    dwnSmplDF = concat_df.groupby('birth_year',group_keys = False).apply(lambda x: x.sample(sample_per_year))\n",
    "    cl_df = dwnSmplDF[cols_to_keep]\n",
    "    encoded_target = dwnSmplDF['admit_NICU']\n",
    "    \n",
    "    glm_lassoCV = linear_model.LogisticRegressionCV(#Cs = int(1e4),\n",
    "                                                cv = 5,\n",
    "                                                penalty = 'l1',\n",
    "                                                solver = 'saga',\n",
    "                                                n_jobs = -1,\n",
    "                                                random_state = 108\n",
    "                                               ).fit(cl_df, encoded_target)\n",
    "    print('sample size : %d\\n' % (sample_per_year*5))\n",
    "    %time glm_lassoCV.fit(cl_df, encoded_target)\n",
    "    print('\\nscore    : {0}'.format(glm_lassoCV.score(cl_df, encoded_target)))\n",
    "    print('-'*50)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of LogisticRegressionCV(Cs=10, class_weight=None, cv=5, dual=False,\n",
       "                     fit_intercept=True, intercept_scaling=1.0, l1_ratios=None,\n",
       "                     max_iter=100, multi_class='warn', n_jobs=-1, penalty='l1',\n",
       "                     random_state=108, refit=True, scoring=None, solver='saga',\n",
       "                     tol=0.0001, verbose=0)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glm_lassoCV.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = glm_lassoCV.predict(cl_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[89800     3   362]\n",
      " [  149  1047     2]\n",
      " [ 6945     0  1692]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(encoded_target,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "glmLCV_coefs = pd.DataFrame({'col' :list(cl_df.columns), \n",
    "                           'coef0': glm_lassoCV.coef_[0], \n",
    "                          'coef1': glm_lassoCV.coef_[1],\n",
    "                          'coef2': glm_lassoCV.coef_[2]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col</th>\n",
       "      <th>coef0</th>\n",
       "      <th>coef1</th>\n",
       "      <th>coef2</th>\n",
       "      <th>abs_coef0</th>\n",
       "      <th>abs_coef1</th>\n",
       "      <th>abs_coef2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>birth_year</td>\n",
       "      <td>-0.002558</td>\n",
       "      <td>-0.005061</td>\n",
       "      <td>0.003098</td>\n",
       "      <td>0.002558</td>\n",
       "      <td>0.005061</td>\n",
       "      <td>0.003098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>birth_month</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>-0.000090</td>\n",
       "      <td>-0.000224</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.000224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>birth_time</td>\n",
       "      <td>-0.000149</td>\n",
       "      <td>0.000606</td>\n",
       "      <td>-0.000045</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.000606</td>\n",
       "      <td>0.000045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>birth_day_of_wk</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>-0.000039</td>\n",
       "      <td>-0.000108</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>birth_place</td>\n",
       "      <td>-0.001669</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>-0.001239</td>\n",
       "      <td>0.001669</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>0.001239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>infant_living_at_report</td>\n",
       "      <td>-0.000385</td>\n",
       "      <td>-0.000048</td>\n",
       "      <td>0.000742</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>infant_breastfed_at_discharge</td>\n",
       "      <td>0.001645</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>-0.001632</td>\n",
       "      <td>0.001645</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.001632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>cigs_before</td>\n",
       "      <td>0.001886</td>\n",
       "      <td>0.007419</td>\n",
       "      <td>-0.002703</td>\n",
       "      <td>0.001886</td>\n",
       "      <td>0.007419</td>\n",
       "      <td>0.002703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101</td>\n",
       "      <td>mothers_bmi_recode</td>\n",
       "      <td>-0.000629</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.000834</td>\n",
       "      <td>0.000629</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.000834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>weight_gain</td>\n",
       "      <td>-0.002771</td>\n",
       "      <td>0.003740</td>\n",
       "      <td>0.003880</td>\n",
       "      <td>0.002771</td>\n",
       "      <td>0.003740</td>\n",
       "      <td>0.003880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               col     coef0     coef1     coef2  abs_coef0  \\\n",
       "0                       birth_year -0.002558 -0.005061  0.003098   0.002558   \n",
       "1                      birth_month  0.000523 -0.000090 -0.000224   0.000523   \n",
       "2                       birth_time -0.000149  0.000606 -0.000045   0.000149   \n",
       "3                  birth_day_of_wk  0.000011 -0.000039 -0.000108   0.000011   \n",
       "4                      birth_place -0.001669  0.000396 -0.001239   0.001669   \n",
       "..                             ...       ...       ...       ...        ...   \n",
       "98         infant_living_at_report -0.000385 -0.000048  0.000742   0.000385   \n",
       "99   infant_breastfed_at_discharge  0.001645 -0.000013 -0.001632   0.001645   \n",
       "100                    cigs_before  0.001886  0.007419 -0.002703   0.001886   \n",
       "101             mothers_bmi_recode -0.000629  0.000257  0.000834   0.000629   \n",
       "102                    weight_gain -0.002771  0.003740  0.003880   0.002771   \n",
       "\n",
       "     abs_coef1  abs_coef2  \n",
       "0     0.005061   0.003098  \n",
       "1     0.000090   0.000224  \n",
       "2     0.000606   0.000045  \n",
       "3     0.000039   0.000108  \n",
       "4     0.000396   0.001239  \n",
       "..         ...        ...  \n",
       "98    0.000048   0.000742  \n",
       "99    0.000013   0.001632  \n",
       "100   0.007419   0.002703  \n",
       "101   0.000257   0.000834  \n",
       "102   0.003740   0.003880  \n",
       "\n",
       "[103 rows x 7 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glmLCV_coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "glmLCV_coefs['abs_coef0'] = glmLCV_coefs['coef0'].apply(abs)\n",
    "glmLCV_coefs['abs_coef1'] = glmLCV_coefs['coef1'].apply(abs)\n",
    "glmLCV_coefs['abs_coef2'] = glmLCV_coefs['coef2'].apply(abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "top20_coef0 = glmLCV_coefs.nlargest(10,'abs_coef0')['col']\n",
    "top20_coef1 = glmLCV_coefs.nlargest(10,'abs_coef1')['col']\n",
    "top20_coef2 = glmLCV_coefs.nlargest(10,'abs_coef2')['col']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77           obst_est_edit_wk\n",
       "76      combined_gestation_wk\n",
       "43               n_prev_cesar\n",
       "60      final_delivery_method\n",
       "71          APGAR_score_10min\n",
       "79          assist_vent_immed\n",
       "82    antibiotics_for_newborn\n",
       "8                mothers_race\n",
       "5                 mothers_age\n",
       "80         assist_vent_after6\n",
       "Name: col, dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top20_coef0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43               n_prev_cesar\n",
       "100               cigs_before\n",
       "25          n_prenatal_visits\n",
       "24     mo_prenatal_care_began\n",
       "0                  birth_year\n",
       "102               weight_gain\n",
       "21         prior_terminations\n",
       "28                  cigs_tri2\n",
       "8                mothers_race\n",
       "29                  cigs_tri3\n",
       "Name: col, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top20_coef1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77           obst_est_edit_wk\n",
       "76      combined_gestation_wk\n",
       "71          APGAR_score_10min\n",
       "60      final_delivery_method\n",
       "79          assist_vent_immed\n",
       "5                 mothers_age\n",
       "82    antibiotics_for_newborn\n",
       "43               n_prev_cesar\n",
       "31                mothers_bmi\n",
       "8                mothers_race\n",
       "Name: col, dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top20_coef2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(set(top20_coef0).union(set(top20_coef1)).union(set(top20_coef2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['assist_vent_immed',\n",
       " 'antibiotics_for_newborn',\n",
       " 'birth_year',\n",
       " 'assist_vent_after6',\n",
       " 'mo_prenatal_care_began',\n",
       " 'prior_terminations',\n",
       " 'mothers_age',\n",
       " 'final_delivery_method',\n",
       " 'n_prev_cesar',\n",
       " 'weight_gain',\n",
       " 'obst_est_edit_wk',\n",
       " 'cigs_tri2',\n",
       " 'mothers_race',\n",
       " 'cigs_before',\n",
       " 'cigs_tri3',\n",
       " 'combined_gestation_wk',\n",
       " 'mothers_bmi',\n",
       " 'n_prenatal_visits',\n",
       " 'APGAR_score_10min']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(top20_coef0).union(set(top20_coef1)).union(set(top20_coef2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['n_prev_cesar', 'mothers_race']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(top20_coef0).intersection(set(top20_coef1)).intersection(set(top20_coef2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "sample size : 100000\n",
    "\n",
    "CPU times: user 54min 1s, sys: 37.3 s, total: 54min 39s\n",
    "Wall time: 8min 39s\n",
    "\n",
    "score    : 0.92512\n",
    "--------------------------------------------------\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GLM with Lasso Penalty and Cross Validation\n",
    "\n",
    "sample_size_list = [200000]\n",
    "\n",
    "for sample_per_year in sample_size_list:\n",
    "    dwnSmplDF = concat_df.groupby('birth_year',group_keys = False).apply(lambda x: x.sample(sample_per_year))\n",
    "    cl_df = dwnSmplDF[cols_to_keep]\n",
    "    encoded_target = dwnSmplDF['admit_NICU']\n",
    "    \n",
    "    glm_lassoCV = linear_model.LogisticRegressionCV(#Cs = int(1e4),\n",
    "                                                cv = 5,\n",
    "                                                penalty = 'l1',\n",
    "                                                solver = 'saga',\n",
    "                                                n_jobs = -2,\n",
    "                                                random_state = 108\n",
    "                                               ).fit(cl_df, encoded_target)\n",
    "    print('sample size : %d\\n' % (sample_per_year*5))\n",
    "    %time glm_lassoCV.fit(cl_df, encoded_target)\n",
    "    print('\\nscore    : {0}'.format(glm_lassoCV.score(cl_df, encoded_target)))\n",
    "    print('-'*50)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for sample_per_year in [100, 1000, 2000, 5000, 10000]:\n",
    "for sample_per_year in [10000]:\n",
    "    dwnSmplDF = concat_df.groupby('birth_year',group_keys = False).apply(lambda x: x.sample(sample_per_year))\n",
    "    \n",
    "    cl_df = dwnSmplDF[cols_to_keep]\n",
    "    encoded_target = dwnSmplDF['admit_NICU']\n",
    "    \n",
    "    randomForest = ensemble.RandomForestClassifier(random_state = 108, warm_start = True)\n",
    "    grid_para_forest = [{\n",
    "        \n",
    "        # fix the numbers as sample size increases\n",
    "#         'n_estimators' : range(1000,10000,1000),\n",
    "        'n_estimators' : np.linspace(10,int(np.sqrt(len(cl_df))),10,dtype=int),\n",
    "#         'min_samples_split' : [100,10,2],\n",
    "        'min_samples_leaf' : range(10,100,10)\n",
    "        \n",
    "    }]\n",
    "    randomForest.set_params(random_state=108)\n",
    "    grid_search_forest = GridSearchCV(randomForest, grid_para_forest, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "    %time grid_search_forest.fit(cl_df, encoded_target) #put in the df here\n",
    "    print(\n",
    "    '''Random Forest\n",
    "sample size: {0}\n",
    "best param : {1}\n",
    "best score : {2}\n",
    "r2         : {3}'''\\\n",
    "      .format(len(encoded_target), \\\n",
    "              grid_search_forest.best_params_,\\\n",
    "              grid_search_forest.best_score_, \\\n",
    "              r2_score(encoded_target, grid_search_forest.predict(cl_df)))\n",
    "     )\n",
    "    print('-'*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_per_year = 10000\n",
    "dwnSmplDF = concat_df.groupby('birth_year',group_keys = False).apply(lambda x: x.sample(sample_per_year))\n",
    "cl_df = dwnSmplDF[cols_to_keep]\n",
    "encoded_target = dwnSmplDF['admit_NICU']\n",
    "best_params = grid_search_forest.best_params_\n",
    "randomForest = ensemble.RandomForestClassifier(random_state = 108, warm_start = True, oob_score = True, **best_params)\n",
    "randomForest.fit(cl_df, encoded_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomForest.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(randomForest.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'col' :list(cl_df.columns), 'feature_importance': list(randomForest.feature_importances_)}\n",
    "importance = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance.nlargest(20,'feature_importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(importance.nlargest(30,'feature_importance')['col'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
